# LLM Provider Configuration
# Supported providers: openai, claude, gemini, ollama, custom

# NOTE: Tested with OpenAI & Gemini.

# OpenAI Configuration (when LLM_PROVIDER=openai)
LLM_PROVIDER=openai
OPENAI_API_KEY=sk-<your_openai_api_key>
OPENAI_MODEL=gpt-4o-mini

# Google Gemini Configuration (when LLM_PROVIDER=gemini)
LLM_PROVIDER=gemini
GOOGLE_API_KEY=your-google-api-key-here
GEMINI_MODEL=gemini-2.5-flash

# Claude/Anthropic Configuration (when LLM_PROVIDER=claude)
LLM_PROVIDER=claude
ANTHROPIC_API_KEY=sk-ant-api03-your-key-here
ANTHROPIC_MODEL=claude-3-5-sonnet-20241022

# Ollama Configuration (when LLM_PROVIDER=ollama)
LLM_PROVIDER=ollama
OLLAMA_BASE_URL=http://localhost:11434/v1
OLLAMA_MODEL=llama3.2

# Custom Provider Configuration (when LLM_PROVIDER=custom)
LLM_PROVIDER=custom
CUSTOM_BASE_URL=http://your-custom-server:port/v1
CUSTOM_API_KEY=your-custom-api-key
CUSTOM_MODEL=your-model-name

